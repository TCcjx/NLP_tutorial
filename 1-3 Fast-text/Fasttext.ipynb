{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Word2Vec的缺点\n",
    "1.无法表示词表中不曾出现的词汇，也就是说几乎不能处理罕见词和未曾见过的词语\n",
    "\n",
    "2.对于同义词问题，无法很好的处理 利于cat 和 cats\n",
    "\n",
    "3.无法捕捉单词的内部结构，导致一些罕见词很能被学习到\n",
    "\n",
    "4.无法直接用于句子或文档级别的表示\n",
    "\n",
    "## Fasttext的改进\n",
    "FastText对单词进行n-gram处理\n",
    "\n",
    "1.这样做可以使得单词对低频词 和 罕见词有更好的处理，因为共享了n-gram的分词表示\n",
    "\n",
    "2.可以动态处理新词汇\n",
    "\n",
    "3.更好的捕捉了单词内部的形态"
   ],
   "id": "a181628ba8738c0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Fasttext的输入部分处理，所谓的词袋法，即将所有文本看成一个词袋（词的集合）进行表示：\n",
    "输入文本: \"I love natural language processing\"\n",
    "1. 分词: [\"I\", \"love\", \"natural\", \"language\", \"processing\"]\n",
    "2. 添加特殊字符: [\"<I>\", \"<love>\", \"<natural>\", \"<language>\", \"<processing>\"]\n",
    "3. 提取 n-gram 特征 (以 3-gram 为例):\n",
    "   - \"<I>\": [\"<I\", \"I>\"]\n",
    "   - \"<love>\": [\"<lo\", \"lov\", \"ove\", \"ve>\"]\n",
    "   - \"<natural>\": [\"<na\", \"nat\", \"atu\", \"tur\", \"ure\", \"re>\"]\n",
    "   - \"<language>\": [\"<la\", \"lan\", \"ang\", \"ngu\", \"gua\", \"uag\", \"age\", \"ge>\"]\n",
    "   - \"<processing>\": [\"<pr\", \"pro\", \"roc\", \"oce\", \"ces\", \"ess\", \"ssi\", \"sin\", \"ing\", \"ng>\"]\n",
    "4. 初始化 n-gram 嵌入向量:\n",
    "   - vector(\"<I\") = [0.1, 0.2, ..., 0.3]\n",
    "   - vector(\"I>\") = [0.4, 0.5, ..., 0.6]\n",
    "   - vector(\"<lo\") = [0.7, 0.8, ..., 0.9]\n",
    "   - ...\n",
    "5. 计算单词向量:\n",
    "   - vector(\"I\") = avg(vector(\"<I\"), vector(\"I>\"))\n",
    "   - vector(\"love\") = avg(vector(\"<lo\"), vector(\"lov\"), vector(\"ove\"), vector(\"ve>\"))\n",
    "   - ...\n",
    "6. 计算文本向量:\n",
    "   - vector(\"I love natural language processing\") = avg(vector(\"I\"), vector(\"love\"), vector(\"natural\"), vector(\"language\"), vector(\"processing\"))"
   ],
   "id": "ee170b6d244e96ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "静态词向量和动态词向量是自然语言处理中两种不同类型的词嵌入方法，它们在训练方式、应用场景和优缺点等方面存在显著区别。以下是它们的详细对比：\n",
    "\n",
    "### 1. **定义**\n",
    "- **静态词向量**：\n",
    "  - 静态词向量是指在训练完成后，词向量在整个模型的使用过程中保持不变。它通常是在一个大规模的语料库上预训练得到的，例如Word2Vec、GloVe等。\n",
    "  - 每个单词在词表中都有一个固定的向量表示，无论它出现在什么上下文中，其向量都是相同的。\n",
    "- **动态词向量**：\n",
    "  - 动态词向量是指词向量在模型的训练和使用过程中会根据上下文动态调整。它通常是在模型的训练过程中与任务一起联合训练得到的，例如BERT、Transformer等预训练模型。\n",
    "  - 同一个单词在不同的上下文中可能会有不同的向量表示。\n",
    "\n",
    "### 2. **训练方式**\n",
    "- **静态词向量**：\n",
    "  - **训练语料**：通常使用独立的、大规模的通用语料库进行预训练，例如维基百科、新闻语料等。\n",
    "  - **训练目标**：主要目标是学习单词之间的共现关系，使得语义相近的单词在向量空间中更接近。\n",
    "  - **训练方法**：常见的方法包括Word2Vec（CBOW和Skip-Gram）、GloVe等。\n",
    "- **动态词向量**：\n",
    "  - **训练语料**：通常与具体任务的语料一起训练，或者在预训练阶段使用大规模语料，但在微调阶段会根据具体任务的语料进行调整。\n",
    "  - **训练目标**：不仅学习单词之间的共现关系，还学习单词在不同上下文中的语义变化。\n",
    "  - **训练方法**：基于Transformer架构的预训练模型（如BERT、RoBERTa等）通过掩码语言模型（Masked Language Model, MLM）等任务进行训练。\n",
    "\n",
    "### 3. **上下文依赖性**\n",
    "- **静态词向量**：\n",
    "  - **上下文无关**：每个单词的向量表示是固定的，不依赖于上下文。例如，“苹果”在“苹果是一种水果”和“苹果公司发布了新产品”中，其向量表示是相同的。\n",
    "- **动态词向量**：\n",
    "  - **上下文相关**：同一个单词在不同的上下文中会有不同的向量表示。例如，“苹果”在上述两个句子中的向量表示会根据上下文动态调整，分别更接近“水果”和“公司”相关的语义。\n",
    "\n",
    "### 4. **应用场景**\n",
    "- **静态词向量**：\n",
    "  - 适用于对上下文依赖性要求不高的任务，例如词性标注、命名实体识别（NER）等。\n",
    "  - 由于其计算效率较高，也常用于一些对实时性要求较高的场景。\n",
    "- **动态词向量**：\n",
    "  - 更适合需要理解上下文语义的任务，例如机器翻译、问答系统、文本分类等。\n",
    "  - 在处理歧义词和多义词时表现更好，因为它们可以根据上下文动态调整词向量。\n",
    "\n",
    "### 5. **优缺点**\n",
    "- **静态词向量**：\n",
    "  - **优点**：\n",
    "    - 计算效率高，训练和使用速度快。\n",
    "    - 模型简单，易于理解和实现。\n",
    "  - **缺点**：\n",
    "    - 缺乏上下文感知能力，无法处理多义词和歧义词。\n",
    "    - 对于罕见词或未登录词的表示能力较差。\n",
    "- **动态词向量**：\n",
    "  - **优点**：\n",
    "    - 强大的上下文感知能力，能够更好地处理多义词和歧义词。\n",
    "    - 在复杂任务中表现更好，能够捕捉更丰富的语义信息。\n",
    "  - **缺点**：\n",
    "    - 计算开销大，训练和推理速度较慢。\n",
    "    - 模型复杂，需要大量的计算资源和数据支持。\n",
    "\n",
    "### 6. **总结**\n",
    "静态词向量和动态词向量各有优缺点，适用于不同的场景。静态词向量适合对上下文依赖性要求不高且对效率要求较高的任务；动态词向量则更适合需要理解上下文语义的复杂任务。在实际应用中，可以根据具体任务的需求选择合适的词向量方法，或者将两者结合使用以达到更好的效果。"
   ],
   "id": "f1ad17fb2a32f312"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
